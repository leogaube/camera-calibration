\documentclass[bibliography=totoc]{scrartcl}
\usepackage[ngerman, english]{babel}
\usepackage{rwukoma}
\usepackage[pdfusetitle]{hyperref}
\usepackage{lipsum,caption}
\usepackage{algorithm, algpseudocode}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{float}
\usepackage{amsmath}
\usepackage{pythonhighlight}

\setlength{\belowcaptionskip}{5pt}

\title{Camera Calibration}
\author{Leopold Gaube - 34948, IN}
\date{\today}

\begin{document}
\maketitle
\tableofcontents

\clearpage

\section{Task Overview}

When taking images or video with a camera, a 3D scene gets projected onto a 2D image.
A simple pinhole camera model is still often used explain the concept of this projection, but nowadays modern cameras use lenses to capture more light.
This gives rise to a problem where supposed straight lines, for instance a door, do appear curved in the resulting image. 
This unwanted effect is called lens distortion and is usually most pronounced with ultrawide lenses.

The following report presents an algorithm to calibrate a camera and undistort images based on this calibration.
Two calibration videos, each depicting a checkerboard pattern in various positions, has been provided by the lecturer of the Computer Vision course.
In both videos Barrel Distortion is clearly visible and its removal is the objective of the hereby presented algorithm.

First, the algorithm extracts appropriate frames from the calibration video.
Then in each calibration frame the checkerboard pattern is localized.
These positions are used to retrieve the intrinsic matrix and distortion coefficients of the camera. 
Together they allow to undistort any image taken with the same camera, which is finally demonstrated on the calibration frames themselves.

The code and all frames used for the camera calibration task are available in this \href{https://gitlab.com/gaubeleo/camera-calibration}{GitLab repository} \cite{Gitlab}.

\section{Frame Selection}
In theory, we only need three frames to retrieve the intrinsic camera matrix.
In practise, more frames give better results and it is also advisable to use frames with the checkerboard present in different parts of the image and with varying distance.
The OpenCV documentation advises to use at least ten images for a camera calibration \cite{CameraCalibration}.
It is possible to manually extract appropriate frames from the calibration video, but we chose to automate this process in order to minimize work for the user in future calibrations. 

Naturally, consecutive frames should not be used, but frames that span the entire video.
For this, the video gets sectioned into 20 evenly spaced time steps and we try to find an appropriate frame for each section.
This way, we get varying checkerboard positions, assuming the checkerboard is being moved around in the calibration video.

Some of the frames may have a lot of motion blur which can be problematic for accurately localizing the checkerboard corners.
Instead of choosing calibration frames in fixed intervals, we consider 25 consecutive candidate frames for each video section (corresponding to one second of video) from which we only choose the least blurred one.
The extent of blur in an image can be calculated using the Variance of Laplacian, with a low variance corresponding to a high amount of blur \cite{BlurDetection}.
With OpenCV it is simple to obtain a focus measure for any greyscale image:\\

\begin{python}
    focus_score = cv2.Laplacian(frame, cv2.CV_64F).var()
\end{python}

The absolute value is of no interest, but the highest value of the 25 candidate frames corresponds to the sharpest one.


\section{Intrinsic Camera Matrix}
The intrinsic matrix is defined as

$$
K =
\begin{pmatrix}
    f_x & 0 & c_x \\
    0 & f_y & c_x \\
    0 & 0 & 1
\end{pmatrix}
$$

with $f_x$, $f_y$ representing the focal length and $c_x$, $c_y$ representing the optical center in x and y direction, respectively \cite{CameraCalibration}.
Together with the distortion coefficients 

$$(k_1, k_2, p_1, p_2, k_3)$$

the intrinsic matrix can be used to undistort images.

K is an upper triangular matrix, therefore, the determinant of K is the product of its trace. 
The focal lengths $f_x$ and $f_y$ are always greater than zero, thus, the determinant of K must be non-zero and K is invertable.
Finding the inverse of K would allow to go from 2D pixel coordinates back to 3D camera coordinates with the restriction that some depth information is lost.

In order to estimate the instrinsic matrix and distortion coefficients, a predefined object has to be detected and localized in the calibration frames.
This algorithm uses a checkerboard as such a predefined object, because it possesses advantagious properties that simplify the calibration process.
Because a checkerboard is flat, all detection points lay on the same plane in equal distance to each other.
Both calibration videos show a board with 8x8 squares, but only corner points of four intersecting squares are used, thus, it depicts a 7x7 pattern.

Unfortunately, even with sharp images it is not guaranteed that OpenCV can always locate the checkerboard.
Successful detections are highly dependant on the size of the pattern. 
Curiously, the 7x7 pattern is rarly detected even when the full checkerboard is clearly visible in the image frame.
Smaller patterns are detected more frequently.
The 6x6 pattern is recognised in some checkerboard positions, but not in others, so a 5x5 pattern is chosen for this algorithm.
Using the adaptiveThreshold and normalizeImage flags also improves the detection consistency.
The 5x5 checkerboard pattern is found in 17 of the 20 sections in the old calibration video and in 12 of the 20 sections in the new one, so both fulfill the OpenCV recommendation of at least ten images.

The cv2.findChessboard() method only localizes the checkerboard pattern in terms of pixel coordinates, which is inprecise.
With cv2.cornerSubPix() these coordinates can be refined to sub-pixel precision.

In addition to the 2D image positions of all detected checkerboards, the corresponding 3D real-world object positions are also needed.
The world coordinate system can be set to any position. 
Canonically, we choose the left top corner of the checkerboard as its origin.
Furthermore, the distance between each checkerboard square is set to be one unit in both x and y direction. 
The checkerboard is flat, which allows all object points to sit on the z=0 plane.
This makes it possible to set identical real-world object positions for all 15 calibration frames.\\

\begin{figure}[ht!]
	\centering
	\includegraphics[width=\linewidth]{imgs/labeled_checkerboard.png}
	\caption{The detected checkerboard corners overlayed with its corresponding object point positions.}
	\label{fig:labeled_checkerboard}
\end{figure}


\section{Undistortion}
With the checkerboard localized in all calibration frames, OpenCV provides a functionality to undistort images in a couple of function calls.
The object positions and corresponding image positions are used as parameters to cv2.calibrateCamera() to obtain the intrinsic camera matrix and distortion coefficients.
These are then used as input to cv2.undistort() to undistort all calibration frames.

In Fig. \ref{fig:comparison} it can be seen that the distortion has been corrected.
It should also be noted that the undistortion process warps the image in a way that some pixels on the image edges have to be discarded to keep a clean rectangular image.\\

\begin{figure}[H]
	\centering
	\begin{subfigure}[t]{0.47\linewidth}
		\includegraphics[width=\linewidth]{imgs/distorted.png}
		\caption{distorted image}
		\label{subfig:distorted}
	\end{subfigure}
	\hspace{0.01\textwidth}
	\begin{subfigure}[t]{0.47\linewidth}
		\includegraphics[width=\linewidth]{imgs/undistorted.png}
		\caption{undistorted image}
		\label{subfig:undistorted}
	\end{subfigure}
    \caption{In the original image (\ref{sub@subfig:distorted}) supposed straight lines appear curved. Undistorting the image (\ref{sub@subfig:undistorted}) resolve this problem. Straight red lines have been overlayed onto both images, to make the distortion more visible.}
	\label{fig:comparison}
\end{figure}

\section{Results}
Together with their originals, four pairs of undistorted images can be found at the end of this report (see Fig.\ref{fig:res1}-\ref{fig:res4}).

The undistorted images look as expected, but in order to objectively measure the quality of the calibration, the 3D real-world object points can be projected back onto the 2D image.
In addition to the intrinsic matrix and distortion coefficients, cv2.calibrateCamera() also returns rotation and translation vectors, which are also needed for cv2.projectPoints().
The closer the projected object points are to the detected checkerboard corners, the smaller the reprojection error and the better the calibration.

\clearpage

The presented algorithm retrieved the following intrinsic matrix for the old video

$$
K =
\begin{pmatrix}
    1259.411 & 0. & 899.046 \\
    0. & 1257.995 & 514.276 \\
    0. & 0. & 1.
\end{pmatrix}
$$

with distortion coefficients
$$(-0.3394, 0.1437, -0.0010, -0.0001, -0.0314)$$
and a mean reprojection error of 0.0372.

For the new video it produced 

$$
K =
\begin{pmatrix}
    1287.686 & 0. & 903.062 \\
    0. & 1288.718 & 505.889 \\
    0. & 0. & 1.
\end{pmatrix}
$$

with distortion coefficients
$$(-0.3644, 0.1787, 0.0010, -0.0011, -0.0518)$$
and a mean reprojection error of 0.02821.

Each intrinsic matrix and distortion coefficients gets saved to a file, as they have to be calculated only once and can be reused to undistort any image, assuming the same camera is being used.


\begin{figure}[H]
	\includegraphics[width=\linewidth]{imgs/old_2547.png}
	\par\bigskip
	\includegraphics[width=\linewidth]{imgs/old2547.png}
	\caption{old video, frame 2547}
	\label{fig:res1}
\end{figure}

\begin{figure}[H]
	\includegraphics[width=\linewidth]{imgs/old_2986.png}
	\par\bigskip
	\includegraphics[width=\linewidth]{imgs/old2986.png}
	\caption{old video, frame 2986}
	\label{fig:res2}
\end{figure}

\begin{figure}[H]
	\includegraphics[width=\linewidth]{imgs/new_1766.png}
	\par\bigskip
	\includegraphics[width=\linewidth]{imgs/new1766.png}
	\caption{new video, frame 1766}
	\label{fig:res3}
\end{figure}

\begin{figure}[H]
	\includegraphics[width=\linewidth]{imgs/new_2259.png}
	\par\bigskip
	\includegraphics[width=\linewidth]{imgs/new2259.png}
	\caption{new video, frame 2259}
	\label{fig:res4}
\end{figure}




\clearpage
\bibliographystyle{alpha}
\bibliography{literature}
\end{document}

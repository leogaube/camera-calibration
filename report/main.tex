\documentclass[bibliography=totoc]{scrartcl}
\usepackage[ngerman, english]{babel}
\usepackage{rwukoma}
\usepackage[pdfusetitle]{hyperref}
\usepackage{lipsum,caption}
\usepackage{algorithm, algpseudocode}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{float}
\usepackage{amsmath}

\setlength{\belowcaptionskip}{5pt}

\title{Camera Calibration}
\author{Leopold Gaube - 34948, IN}
\date{\today}
\begin{document}
\maketitle
\tableofcontents

\clearpage

\section{Introduction}

When taking images or video with a camera, a 3D scene gets projected onto a 2D image.
Naturally, this is accompanied with a loss in information as the distance of an object to the camera is lost.
Therefore, a perfect reconstruction of the original 3D scene from a 2D image is impossible. 
However, ...

Another problem is that some supposed straight lines, e.g. a door, do not appear to be straight in the resulting image. 
This is due to lens distortions. (would not have been an issue with pinhole camera model) 
The provided video footage has been captured with a ultrawide lens, thus it suffers from Barrel Distortion.

(radial and tangential distortion)

In order to undistort the images, we first have to retrieve the intrinsic matrix K 


- 3D scene projected onto 2D image (loss of information)
- distortions
- intrinsic and extrinsic camera parameters
- easily recognisable patterns, OpenCV uses a simple checkerboard pattern. (printed, flat)
- can be used to undistort images/frames

Problem: We usually don't manufacture the sensor ourself
How to calculate K and (R, t)

\cite{OpenCV}
The code and all frames used for this camera calibration task are available in this \href{https://gitlab.com/gaubeleo/camera-calibration}{GitLab repository} \cite{Gitlab}.


\section{Task Overview}
- multiple images (minimum of 3?) of a known object
- best results if taken from various positions
- compute camera matrix, distorition parameters?, rotation and translational vectors (extrinsics?)
- finally, remove distortion

\section{Frame Selection}
In theory, we only need three frames to retrieve the intrinsic camera matrix. (why?)
In practise, more frames give better results and it is also advisable to use frames with the checkerboard present in different parts of the image.
It is possible to manually extract appropriate frames from the calibration video, but we chose to automate this process in order to minimize work for the user for future camera calibrations. 

First we have to specify how many calibration frames should be used. 
For our algorithm we have settled on 15, as this creates good results in a reasonable execution time.
Naturally, we do not want to use consecutive frames, but frames that span the entire video. 
This way, we get varying checkerboard positions (assuming the checkerboard is being moved around in the calibration video).

Some of them may have a lot of motion blur which can be problematic for accurately localizing the checkerboard corners.
So instead, for each evenly spaced time step of the video, we consider 50 consecutive candidate frames (corresponding to two seconds of video) from which we only choose the least blurred one.
The extend of blur in an image can be calculated using the Variance of Laplacian. \cite{BlurDetection}
With OpenCV it is simple to obtain a focus measure for any greyscale image:

\begin{lstlisting}
    focus_score = cv2.Laplacian(frame, cv2.CV_64F).var()
\end{lstlisting}

The absolute value is of no interest, but the highest value of our 50 candidate frames corresponds to the sharpest one.

\section{Intrinsic Camera Matrix}
$$
K =
\begin{pmatrix}
    f * k_1 & 0 & s_1 \\
    0 & f * k_2 & s_2 \\
    0 & 0 & 1
\end{pmatrix}
$$


K is an upper triangular matrix, therefore, the determinant of K is the product of its trace, which is always non-zero because the focal point f, as well as $k_1$ and $k_2$ (and theta?) is greater than 0.

K: focal length, mm step size, sheering angle translation --> intrinsic parameters, only 5 DoF not 6! because we dont care about the individual parameters themself, only the resulting matrix which is a combination of these parameters


Our Algorithm retrieve the following intrinsic matrix:

$$
K =
\begin{pmatrix}
    f * k_1 & 0 & s_1 \\
    0 & f * k_2 & s_2 \\
    0 & 0 & 1
\end{pmatrix}
$$

$K$ has to be calculated only once and can be reused in a different scene assuming the same camera is being used.


\section{Undistorting}



\clearpage
\section*{List of Acronyms}
\addcontentsline{toc}{section}{List of Acronyms}

\bibliographystyle{alpha}
\bibliography{literature}
\end{document}
